{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéôÔ∏è Qwen3 TTS Server for Social Video Engine\n",
        "\n",
        "This notebook runs Qwen3-TTS as an API server on Google Colab (free GPU).\n",
        "\n",
        "**How it works:**\n",
        "1. Loads the Qwen3-TTS model on the Colab T4 GPU\n",
        "2. Exposes an HTTP API via ngrok\n",
        "3. Your video pipeline sends text ‚Üí gets back audio\n",
        "4. **Cost: $0.00**\n",
        "\n",
        "**Setup:**\n",
        "1. Make sure GPU runtime is enabled: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "2. Run all cells\n",
        "3. Copy the ngrok URL and set it in your render pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install dependencies\n",
        "!pip install -q qwen-tts flask pyngrok soundfile numpy torch\n",
        "!pip install -q flash-attn --no-build-isolation 2>/dev/null || echo 'Flash attention install failed, continuing without it'"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Check GPU\n",
        "import torch\n",
        "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB')\n",
        "print(f'PyTorch: {torch.__version__}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load model (downloads ~1.5GB on first run)\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "import torch\n",
        "\n",
        "# Use 0.6B for free Colab (less VRAM), 1.7B for paid/Pro\n",
        "MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice\"\n",
        "# MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"  # Uncomment for better quality\n",
        "\n",
        "try:\n",
        "    model = Qwen3TTSModel.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        device_map=\"cuda:0\",\n",
        "        dtype=torch.bfloat16,\n",
        "        attn_implementation=\"flash_attention_2\",\n",
        "    )\n",
        "except Exception:\n",
        "    print(\"Flash attention not available, using default\")\n",
        "    model = Qwen3TTSModel.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        device_map=\"cuda:0\",\n",
        "        dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "print(f'‚úÖ Model loaded: {MODEL_NAME}')\n",
        "print(f'Speakers: {model.get_supported_speakers()}')\n",
        "print(f'Languages: {model.get_supported_languages()}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Quick test ‚Äî generate a sample\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "\n",
        "wavs, sr = model.generate_custom_voice(\n",
        "    text=\"AI automation saves businesses over twenty hours every single week. And the best part? It costs almost nothing to get started.\",\n",
        "    language=\"English\",\n",
        "    speaker=\"Ryan\",\n",
        "    instruct=\"Speak with confidence and enthusiasm, like a tech YouTuber.\",\n",
        ")\n",
        "\n",
        "sf.write(\"/tmp/test_qwen_tts.wav\", wavs[0], sr)\n",
        "print(f'‚úÖ Generated {len(wavs[0])/sr:.1f}s of audio')\n",
        "Audio(wavs[0], rate=sr)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Start the API server\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import base64\n",
        "import threading\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({'status': 'ok', 'model': MODEL_NAME})\n",
        "\n",
        "@app.route('/speakers', methods=['GET'])\n",
        "def speakers():\n",
        "    return jsonify({\n",
        "        'speakers': model.get_supported_speakers(),\n",
        "        'languages': model.get_supported_languages(),\n",
        "    })\n",
        "\n",
        "@app.route('/tts', methods=['POST'])\n",
        "def tts():\n",
        "    \"\"\"\n",
        "    Generate TTS audio.\n",
        "    \n",
        "    Body JSON:\n",
        "    {\n",
        "        \"text\": \"Text to speak\",\n",
        "        \"speaker\": \"Ryan\",        // Ryan, Aiden, Vivian, etc.\n",
        "        \"language\": \"English\",     // English, Chinese, Arabic, etc.\n",
        "        \"instruct\": \"Speak with confidence\",  // Optional style instruction\n",
        "        \"format\": \"wav\"           // wav (default) or base64\n",
        "    }\n",
        "    \"\"\"\n",
        "    data = request.json\n",
        "    text = data.get('text', '')\n",
        "    speaker = data.get('speaker', 'Ryan')\n",
        "    language = data.get('language', 'English')\n",
        "    instruct = data.get('instruct', '')\n",
        "    output_format = data.get('format', 'wav')\n",
        "    \n",
        "    if not text:\n",
        "        return jsonify({'error': 'text is required'}), 400\n",
        "    \n",
        "    try:\n",
        "        wavs, sr = model.generate_custom_voice(\n",
        "            text=text,\n",
        "            language=language,\n",
        "            speaker=speaker,\n",
        "            instruct=instruct if instruct else None,\n",
        "        )\n",
        "        \n",
        "        audio_data = wavs[0]\n",
        "        duration = len(audio_data) / sr\n",
        "        \n",
        "        if output_format == 'base64':\n",
        "            buf = io.BytesIO()\n",
        "            sf.write(buf, audio_data, sr, format='WAV')\n",
        "            buf.seek(0)\n",
        "            b64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "            return jsonify({\n",
        "                'audio_base64': b64,\n",
        "                'sample_rate': sr,\n",
        "                'duration': duration,\n",
        "                'format': 'wav'\n",
        "            })\n",
        "        else:\n",
        "            buf = io.BytesIO()\n",
        "            sf.write(buf, audio_data, sr, format='WAV')\n",
        "            buf.seek(0)\n",
        "            return send_file(buf, mimetype='audio/wav',\n",
        "                           download_name='tts_output.wav')\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/tts/batch', methods=['POST'])\n",
        "def tts_batch():\n",
        "    \"\"\"\n",
        "    Batch TTS for multiple scenes.\n",
        "    \n",
        "    Body JSON:\n",
        "    {\n",
        "        \"scenes\": [\n",
        "            {\"text\": \"...\", \"speaker\": \"Ryan\", \"instruct\": \"...\"},\n",
        "            {\"text\": \"...\", \"speaker\": \"Ryan\", \"instruct\": \"...\"}\n",
        "        ],\n",
        "        \"language\": \"English\",\n",
        "        \"format\": \"base64\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    data = request.json\n",
        "    scenes = data.get('scenes', [])\n",
        "    language = data.get('language', 'English')\n",
        "    \n",
        "    results = []\n",
        "    for scene in scenes:\n",
        "        try:\n",
        "            wavs, sr = model.generate_custom_voice(\n",
        "                text=scene['text'],\n",
        "                language=language,\n",
        "                speaker=scene.get('speaker', 'Ryan'),\n",
        "                instruct=scene.get('instruct', '') or None,\n",
        "            )\n",
        "            buf = io.BytesIO()\n",
        "            sf.write(buf, wavs[0], sr, format='WAV')\n",
        "            buf.seek(0)\n",
        "            b64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "            results.append({\n",
        "                'audio_base64': b64,\n",
        "                'duration': len(wavs[0]) / sr,\n",
        "                'success': True\n",
        "            })\n",
        "        except Exception as e:\n",
        "            results.append({'error': str(e), 'success': False})\n",
        "    \n",
        "    return jsonify({'results': results, 'sample_rate': sr})\n",
        "\n",
        "# Run Flask in a thread\n",
        "threading.Thread(target=lambda: app.run(port=5000, debug=False), daemon=True).start()\n",
        "print('‚úÖ Flask server running on port 5000')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Expose via ngrok (free)\n",
        "# Get your free ngrok token at https://ngrok.com (sign up, copy authtoken)\n",
        "NGROK_TOKEN = \"\"  # Paste your ngrok token here\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "if NGROK_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f'\\nüåê TTS API is live at: {public_url}')\n",
        "print(f'\\nTest it:')\n",
        "print(f'  curl -X POST {public_url}/tts \\\\')\n",
        "print(f'    -H \"Content-Type: application/json\" \\\\')\n",
        "print(f'    -d \\'{{\"text\": \"Hello world\", \"speaker\": \"Ryan\"}}\\' \\\\')\n",
        "print(f'    --output test.wav')\n",
        "print(f'\\nüìã Set this URL in your video pipeline config.')\n",
        "print(f'\\n‚ö†Ô∏è  Keep this notebook running! Close it = API goes down.')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Keep alive ‚Äî run this to prevent Colab from timing out\n",
        "import time\n",
        "print('Keeping session alive... (Ctrl+C to stop)')\n",
        "while True:\n",
        "    time.sleep(60)\n",
        "    print(f'[{time.strftime(\"%H:%M\")}] Server alive at {public_url}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
