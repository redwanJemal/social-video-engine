{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Social Video Engine\n",
    "\n",
    "**AI-powered social video generator with Qwen3-TTS + Remotion**\n",
    "\n",
    "Generate professional animated short-form videos (Reels/TikTok/Shorts) with natural AI voiceover.\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Story Script ‚Üí Qwen3-TTS (voiceover) ‚Üí Remotion (React animations) ‚Üí FFmpeg (merge) ‚Üí Final MP4\n",
    "```\n",
    "\n",
    "**Cost: $0.00 per video** (runs entirely on Colab's free GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Environment\n",
    "Installs Node.js, Chromium, Qwen3-TTS, and clones the video engine repo.\n",
    "\n",
    "‚è±Ô∏è Takes ~5-7 minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"üîß Installing Node.js 20...\"\n",
    "curl -fsSL https://deb.nodesource.com/setup_20.x | bash - > /dev/null 2>&1\n",
    "apt-get install -y nodejs > /dev/null 2>&1\n",
    "echo \"  Node: $(node -v)\"\n",
    "echo \"  npm: $(npm -v)\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"üîß Installing Chromium for Remotion...\"\n",
    "apt-get install -y chromium-browser > /dev/null 2>&1 || apt-get install -y chromium > /dev/null 2>&1\n",
    "echo \"  Chromium: $(chromium-browser --version 2>/dev/null || chromium --version 2>/dev/null || echo 'using bundled')\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"üîß FFmpeg check...\"\n",
    "echo \"  FFmpeg: $(ffmpeg -version 2>&1 | head -1)\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ System dependencies ready!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Social Video Engine repo\n",
    "import os\n",
    "\n",
    "REPO_DIR = \"/content/social-video-engine\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/redwanJemal/social-video-engine.git {REPO_DIR}\n",
    "    !cd {REPO_DIR} && npm install --legacy-peer-deps 2>&1 | tail -3\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "    print(\"Repo already cloned\")\n",
    "\n",
    "print(f\"\\n‚úÖ Video engine ready at {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Qwen3-TTS\n",
    "!pip install -U qwen-tts soundfile numpy > /dev/null 2>&1\n",
    "\n",
    "# Try installing flash-attention (speeds up inference, optional)\n",
    "try:\n",
    "    !MAX_JOBS=2 pip install flash-attn --no-build-isolation > /dev/null 2>&1\n",
    "    print(\"‚úÖ flash-attn installed\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è flash-attn failed (will use default attention ‚Äî still works fine)\")\n",
    "\n",
    "import torch\n",
    "print(f\"\\nüñ•Ô∏è GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "print(f\"\\n‚úÖ Qwen3-TTS ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load TTS Model\n",
    "\n",
    "Choose your model:\n",
    "- **CustomVoice** (recommended) ‚Äî 9 premium voices with mood/style control\n",
    "- **VoiceDesign** ‚Äî describe any voice you want in text\n",
    "- **Base** ‚Äî clone any voice from 3-second audio sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# ===== CHOOSE MODEL =====\n",
    "MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
    "# MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\"\n",
    "# MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice\"  # Lighter, if T4 runs out of VRAM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "\n",
    "# Try flash_attention_2, fall back to default\n",
    "try:\n",
    "    model = Qwen3TTSModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"cuda:0\",\n",
    "        dtype=torch.bfloat16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "    )\n",
    "except Exception:\n",
    "    model = Qwen3TTSModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"cuda:0\",\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "if \"CustomVoice\" in MODEL_NAME:\n",
    "    print(f\"üé§ Speakers: {model.get_supported_speakers()}\")\n",
    "    print(f\"üåç Languages: {model.get_supported_languages()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Define Your Video\n",
    "\n",
    "### Available Remotion Templates\n",
    "| Template | Description |\n",
    "|----------|-------------|\n",
    "| `intro` | Dramatic hook with ring animation |\n",
    "| `kinetic-text` | Words flying in with spring physics |\n",
    "| `stat-card` | Animated number counters |\n",
    "| `list-reveal` | Items appearing one by one |\n",
    "| `quote-card` | Testimonial with quotation marks |\n",
    "| `cta` | Pulsing call-to-action button |\n",
    "\n",
    "### Available TTS Speakers\n",
    "| Speaker | Voice | Best For |\n",
    "|---------|-------|----------|\n",
    "| **Ryan** | Dynamic male, strong rhythm | Narration, energy |\n",
    "| **Aiden** | Sunny American male | Friendly, casual |\n",
    "| **Vivian** | Bright young female | Engaging, punchy |\n",
    "| **Serena** | Warm gentle female | Calm, storytelling |\n",
    "\n",
    "### Available Themes\n",
    "`midnight` `ocean` `sunset` `forest` `noir` `fire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DEFINE YOUR VIDEO =====\n",
    "# Each scene has: template props + TTS narration\n",
    "\n",
    "VIDEO_CONFIG = {\n",
    "    \"theme\": {\n",
    "        \"name\": \"Midnight\",\n",
    "        \"bgGradient\": [\"#0f0c29\", \"#302b63\"],\n",
    "        \"textColor\": \"#ffffff\",\n",
    "        \"accentColor\": \"#f5576c\",\n",
    "        \"fontFamily\": \"sans-serif\"\n",
    "    },\n",
    "    \"scenes\": [\n",
    "        {\n",
    "            \"type\": \"intro\",\n",
    "            \"duration\": 90,  # frames (30fps) = 3 seconds\n",
    "            \"props\": {\n",
    "                \"hook\": \"Stop scrolling.\",\n",
    "                \"subtitle\": \"This changes everything\"\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Stop scrolling. This is going to change everything you know about productivity.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Dramatic, attention-grabbing, confident.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"kinetic-text\",\n",
    "            \"duration\": 120,  # 4 seconds\n",
    "            \"props\": {\n",
    "                \"lines\": [\"Most people waste\", \"3 HOURS a day\", \"on tasks AI can do\", \"in 3 MINUTES\"],\n",
    "                \"accentLineIndex\": 1,\n",
    "                \"animation\": \"slide-up\"\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Most people waste three hours every single day on tasks that AI can finish in just three minutes.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Building intensity, emphasize the contrast between hours and minutes.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"stat-card\",\n",
    "            \"duration\": 120,  # 4 seconds\n",
    "            \"props\": {\n",
    "                \"title\": \"The Numbers Don't Lie\",\n",
    "                \"stats\": [\n",
    "                    {\"value\": \"87%\", \"label\": \"Time Saved\"},\n",
    "                    {\"value\": \"10x\", \"label\": \"More Output\"},\n",
    "                    {\"value\": \"$0\", \"label\": \"Extra Cost\"}\n",
    "                ]\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Eighty-seven percent time saved. Ten times more output. And it costs you absolutely nothing extra.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Confident, data-driven, impressive.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"list-reveal\",\n",
    "            \"duration\": 150,  # 5 seconds\n",
    "            \"props\": {\n",
    "                \"title\": \"Top 3 AI Tools\",\n",
    "                \"items\": [\"ChatGPT for writing\", \"Midjourney for design\", \"Cursor for coding\"],\n",
    "                \"icon\": \"üöÄ\",\n",
    "                \"numbered\": True\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Here are the top three AI tools you need right now. Number one: ChatGPT for writing. Number two: Midjourney for design. And number three: Cursor for coding.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Enthusiastic, listing items with clear pauses between each.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"quote-card\",\n",
    "            \"duration\": 120,  # 4 seconds\n",
    "            \"props\": {\n",
    "                \"quote\": \"AI won't replace you. But someone using AI will.\",\n",
    "                \"author\": \"Tech Industry\",\n",
    "                \"role\": \"Common saying\"\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Remember this: AI won't replace you. But someone using AI, definitely will.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Thoughtful pause before the punchline, serious tone.\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"cta\",\n",
    "            \"duration\": 90,  # 3 seconds\n",
    "            \"props\": {\n",
    "                \"headline\": \"Start Today\",\n",
    "                \"subtext\": \"Follow for more AI tips\",\n",
    "                \"buttonText\": \"Follow ‚Üí\"\n",
    "            },\n",
    "            \"tts\": {\n",
    "                \"text\": \"Follow for more AI tips that actually save you time. See you in the next one.\",\n",
    "                \"speaker\": \"Ryan\",\n",
    "                \"instruct\": \"Warm, inviting, friendly call to action.\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "total_frames = sum(s[\"duration\"] for s in VIDEO_CONFIG[\"scenes\"])\n",
    "print(f\"üìã Video: {len(VIDEO_CONFIG['scenes'])} scenes, {total_frames} frames ({total_frames/30:.1f}s)\")\n",
    "print(f\"üé® Theme: {VIDEO_CONFIG['theme']['name']}\")\n",
    "for i, s in enumerate(VIDEO_CONFIG[\"scenes\"]):\n",
    "    print(f\"   {i+1}. [{s['type']}] {s['duration']/30:.1f}s ‚Äî {s['tts']['speaker']}: \\\"{s['tts']['text'][:50]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Generate Voiceover\n",
    "Generates TTS audio for each scene using Qwen3-TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "AUDIO_DIR = \"/content/social-video-engine/public/audio\"\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "print(\"üéôÔ∏è Generating voiceover for each scene...\\n\")\n",
    "\n",
    "for i, scene in enumerate(VIDEO_CONFIG[\"scenes\"]):\n",
    "    tts = scene[\"tts\"]\n",
    "    print(f\"  Scene {i+1}/{len(VIDEO_CONFIG['scenes'])}: [{scene['type']}] {tts['speaker']}\")\n",
    "    print(f\"    \\\"{tts['text'][:70]}...\\\"\")\n",
    "    \n",
    "    wavs, sr = model.generate_custom_voice(\n",
    "        text=tts[\"text\"],\n",
    "        language=\"English\",\n",
    "        speaker=tts[\"speaker\"],\n",
    "        instruct=tts.get(\"instruct\", \"\"),\n",
    "    )\n",
    "    \n",
    "    audio_file = f\"{AUDIO_DIR}/scene_{i:03d}.wav\"\n",
    "    sf.write(audio_file, wavs[0], sr)\n",
    "    duration_s = len(wavs[0]) / sr\n",
    "    print(f\"    ‚úÖ {duration_s:.1f}s ‚Üí {audio_file}\")\n",
    "    \n",
    "    # Store audio duration to adjust video scene length\n",
    "    scene[\"audio_duration\"] = duration_s\n",
    "    scene[\"audio_file\"] = f\"audio/scene_{i:03d}.wav\"\n",
    "    print()\n",
    "\n",
    "# Preview the last generated audio\n",
    "print(\"\\nüîä Preview (last scene):\")\n",
    "display(Audio(wavs[0], rate=sr))\n",
    "\n",
    "print(\"\\n‚úÖ All voiceovers generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Adjust Scene Durations to Match Audio\n",
    "Auto-adjusts video scene lengths to match the TTS audio durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30\n",
    "PADDING_FRAMES = 15  # 0.5s padding per scene\n",
    "\n",
    "print(\"‚è±Ô∏è Adjusting scene durations to match audio:\\n\")\n",
    "\n",
    "for i, scene in enumerate(VIDEO_CONFIG[\"scenes\"]):\n",
    "    audio_dur = scene.get(\"audio_duration\", scene[\"duration\"] / FPS)\n",
    "    audio_frames = int(audio_dur * FPS) + PADDING_FRAMES\n",
    "    old_dur = scene[\"duration\"]\n",
    "    scene[\"duration\"] = max(audio_frames, old_dur)  # Use whichever is longer\n",
    "    print(f\"  Scene {i+1} [{scene['type']}]: {old_dur/FPS:.1f}s ‚Üí {scene['duration']/FPS:.1f}s (audio: {audio_dur:.1f}s)\")\n",
    "\n",
    "total_frames = sum(s[\"duration\"] for s in VIDEO_CONFIG[\"scenes\"])\n",
    "print(f\"\\nüìä Total video: {total_frames} frames = {total_frames/FPS:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Render Video with Remotion\n",
    "Renders the React animations to MP4 using Remotion + Chromium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "REPO_DIR = \"/content/social-video-engine\"\n",
    "CONFIG_FILE = f\"{REPO_DIR}/render-config.json\"\n",
    "VIDEO_OUTPUT = f\"{REPO_DIR}/out/video-no-audio.mp4\"\n",
    "\n",
    "# Write config for Remotion (strip TTS-specific fields)\n",
    "remotion_config = {\n",
    "    \"theme\": VIDEO_CONFIG[\"theme\"],\n",
    "    \"scenes\": [\n",
    "        {\"type\": s[\"type\"], \"duration\": s[\"duration\"], \"props\": s[\"props\"]}\n",
    "        for s in VIDEO_CONFIG[\"scenes\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(CONFIG_FILE, \"w\") as f:\n",
    "    json.dump(remotion_config, f, indent=2)\n",
    "\n",
    "print(f\"üìù Config written to {CONFIG_FILE}\")\n",
    "print(f\"üé¨ Rendering {sum(s['duration'] for s in remotion_config['scenes'])} frames...\\n\")\n",
    "\n",
    "# Render with Remotion\n",
    "!cd {REPO_DIR} && node render.mjs --config render-config.json --output {VIDEO_OUTPUT}\n",
    "\n",
    "import os\n",
    "if os.path.exists(VIDEO_OUTPUT):\n",
    "    size_mb = os.path.getsize(VIDEO_OUTPUT) / 1e6\n",
    "    print(f\"\\n‚úÖ Video rendered: {VIDEO_OUTPUT} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Render failed ‚Äî check output above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Merge Audio + Video\n",
    "Combines the Remotion video with the Qwen3-TTS voiceover using FFmpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "AUDIO_DIR = \"/content/social-video-engine/public/audio\"\n",
    "FINAL_OUTPUT = \"/content/social-video-engine/out/final-video.mp4\"\n",
    "FPS = 30\n",
    "\n",
    "# Step 1: Concatenate all scene audio with proper gaps\n",
    "print(\"üîä Building audio track...\")\n",
    "\n",
    "# Create silence-padded audio segments matching scene durations\n",
    "audio_segments = []\n",
    "for i, scene in enumerate(VIDEO_CONFIG[\"scenes\"]):\n",
    "    scene_audio = f\"{AUDIO_DIR}/scene_{i:03d}.wav\"\n",
    "    scene_dur = scene[\"duration\"] / FPS  # target duration in seconds\n",
    "    \n",
    "    if os.path.exists(scene_audio):\n",
    "        # Read audio\n",
    "        data, sr = sf.read(scene_audio)\n",
    "        audio_dur = len(data) / sr\n",
    "        \n",
    "        # Pad with silence to match scene duration\n",
    "        target_samples = int(scene_dur * sr)\n",
    "        if len(data) < target_samples:\n",
    "            padding = np.zeros(target_samples - len(data), dtype=data.dtype)\n",
    "            data = np.concatenate([data, padding])\n",
    "        else:\n",
    "            data = data[:target_samples]\n",
    "        \n",
    "        audio_segments.append(data)\n",
    "        print(f\"  Scene {i+1}: {audio_dur:.1f}s audio ‚Üí padded to {scene_dur:.1f}s\")\n",
    "    else:\n",
    "        # No audio ‚Äî pure silence\n",
    "        silence = np.zeros(int(scene_dur * 24000), dtype=np.float32)  # assume 24kHz\n",
    "        audio_segments.append(silence)\n",
    "        print(f\"  Scene {i+1}: silence ({scene_dur:.1f}s)\")\n",
    "\n",
    "# Concatenate all\n",
    "full_audio = np.concatenate(audio_segments)\n",
    "full_audio_path = f\"{AUDIO_DIR}/full_narration.wav\"\n",
    "sf.write(full_audio_path, full_audio, sr)\n",
    "print(f\"\\n  Full audio: {len(full_audio)/sr:.1f}s ‚Üí {full_audio_path}\")\n",
    "\n",
    "# Step 2: Merge video + audio with FFmpeg\n",
    "print(f\"\\nüé¨ Merging video + audio...\")\n",
    "cmd = [\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", VIDEO_OUTPUT,\n",
    "    \"-i\", full_audio_path,\n",
    "    \"-c:v\", \"copy\",\n",
    "    \"-c:a\", \"aac\",\n",
    "    \"-b:a\", \"192k\",\n",
    "    \"-shortest\",\n",
    "    FINAL_OUTPUT\n",
    "]\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if os.path.exists(FINAL_OUTPUT):\n",
    "    size_mb = os.path.getsize(FINAL_OUTPUT) / 1e6\n",
    "    print(f\"\\n‚úÖ Final video: {FINAL_OUTPUT} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå FFmpeg failed:\\n{result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Preview & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Preview in notebook\n",
    "if os.path.exists(FINAL_OUTPUT):\n",
    "    mp4 = open(FINAL_OUTPUT, 'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    display(HTML(f\"\"\"\n",
    "    <video width=\"360\" height=\"640\" controls autoplay>\n",
    "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\"))\n",
    "else:\n",
    "    print(\"No video to preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download final video\n",
    "from google.colab import files\n",
    "\n",
    "if os.path.exists(FINAL_OUTPUT):\n",
    "    files.download(FINAL_OUTPUT)\n",
    "    print(\"üì• Downloading...\")\n",
    "else:\n",
    "    print(\"No video to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Quick Re-render\n",
    "Edit the `VIDEO_CONFIG` in cell 3, then run cells 4‚Üí8 again.\n",
    "\n",
    "## üí° Tips\n",
    "- **Change theme**: Edit `VIDEO_CONFIG[\"theme\"]` ‚Äî try `ocean`, `sunset`, `forest`, `noir`, `fire`\n",
    "- **Change voice**: Swap `speaker` in any scene's `tts` config\n",
    "- **Add scenes**: Add more entries to the `scenes` list\n",
    "- **Mood control**: The `instruct` field controls speaking style\n",
    "- **Voice clone**: Switch to `Base` model and use `generate_voice_clone()` with a 3s audio sample\n",
    "- **Batch videos**: Loop over multiple `VIDEO_CONFIG`s in a for loop\n",
    "\n",
    "## üé§ All Speakers\n",
    "| Speaker | Voice | Native |\n",
    "|---------|-------|--------|\n",
    "| Ryan | Dynamic male | English |\n",
    "| Aiden | Sunny American male | English |\n",
    "| Vivian | Bright young female | Chinese |\n",
    "| Serena | Warm gentle female | Chinese |\n",
    "| Uncle_Fu | Seasoned male, low | Chinese |\n",
    "| Dylan | Youthful Beijing male | Chinese |\n",
    "| Eric | Lively Chengdu male | Chinese |\n",
    "| Ono_Anna | Playful female | Japanese |\n",
    "| Sohee | Warm female | Korean |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "name": "Social Video Engine ‚Äî Qwen3-TTS + Remotion"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
