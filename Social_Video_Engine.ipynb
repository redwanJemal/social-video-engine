{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Social Video Engine\n",
    "\n",
    "**AI-powered social video generator: Qwen3-TTS + Remotion**\n",
    "\n",
    "```\n",
    "Story Script ‚Üí Qwen3-TTS (voiceover) ‚Üí Remotion (React animations) ‚Üí FFmpeg (merge) ‚Üí Final MP4\n",
    "```\n",
    "\n",
    "**Cost: $0.00 per video** ‚Äî runs on Colab's free GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 ‚Äî Install Everything\n",
    "‚è±Ô∏è ~5-7 min on first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "echo \"üì¶ Node.js...\"\n",
    "if ! command -v node &>/dev/null; then\n",
    "  curl -fsSL https://deb.nodesource.com/setup_20.x | bash - > /dev/null 2>&1\n",
    "  apt-get install -y nodejs > /dev/null 2>&1\n",
    "fi\n",
    "echo \"  $(node -v) / npm $(npm -v)\"\n",
    "\n",
    "echo \"üì¶ Chrome dependencies...\"\n",
    "apt-get update -qq > /dev/null 2>&1\n",
    "apt-get install -y -qq libnss3 libdbus-1-3 libatk1.0-0 libgbm-dev libasound2 \\\n",
    "  libxrandr2 libxkbcommon-dev libxfixes3 libxcomposite1 libxdamage1 \\\n",
    "  libatk-bridge2.0-0 libpango-1.0-0 libcairo2 libcups2 > /dev/null 2>&1\n",
    "echo \"  ‚úÖ deps installed\"\n",
    "\n",
    "echo \"üì¶ FFmpeg: $(ffmpeg -version 2>&1 | head -1)\"\n",
    "echo \"‚úÖ System ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "REPO = \"/content/social-video-engine\"\n",
    "\n",
    "# Clone or update repo\n",
    "if not os.path.exists(REPO):\n",
    "    !git clone https://github.com/redwanJemal/social-video-engine.git {REPO}\n",
    "else:\n",
    "    !cd {REPO} && git pull\n",
    "\n",
    "# Install + upgrade Remotion to latest\n",
    "!cd {REPO} && npm install @remotion/cli@latest @remotion/bundler@latest @remotion/renderer@latest remotion@latest --legacy-peer-deps 2>&1 | tail -3\n",
    "\n",
    "# Download Remotion's Chrome Headless Shell\n",
    "!cd {REPO} && npx remotion browser ensure 2>&1 | tail -3\n",
    "\n",
    "print(f\"\\n‚úÖ Video engine ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Qwen3-TTS\n",
    "!pip install -q -U qwen-tts soundfile numpy\n",
    "\n",
    "# Flash attention (optional, speeds up TTS)\n",
    "!MAX_JOBS=2 pip install -q flash-attn --no-build-isolation 2>/dev/null || echo \"flash-attn skipped (still works fine)\"\n",
    "\n",
    "import torch\n",
    "print(f\"üñ•Ô∏è GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB)\")\n",
    "print(\"‚úÖ TTS ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 ‚Äî Load TTS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, soundfile as sf, numpy as np\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "MODEL = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
    "\n",
    "print(f\"Loading {MODEL}...\")\n",
    "try:\n",
    "    model = Qwen3TTSModel.from_pretrained(MODEL, device_map=\"cuda:0\", dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\")\n",
    "except:\n",
    "    model = Qwen3TTSModel.from_pretrained(MODEL, device_map=\"cuda:0\", dtype=torch.bfloat16)\n",
    "\n",
    "print(f\"‚úÖ Loaded | Speakers: {model.get_supported_speakers()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 ‚Äî Define Your Video\n",
    "\n",
    "**Templates:** `intro` ¬∑ `kinetic-text` ¬∑ `stat-card` ¬∑ `list-reveal` ¬∑ `quote-card` ¬∑ `cta`\n",
    "\n",
    "**Speakers:** `Ryan` (dynamic M) ¬∑ `Aiden` (sunny M) ¬∑ `Vivian` (bright F) ¬∑ `Serena` (warm F)\n",
    "\n",
    "**Themes:** `midnight` ¬∑ `ocean` ¬∑ `sunset` ¬∑ `forest` ¬∑ `noir` ¬∑ `fire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_CONFIG = {\n",
    "    \"theme\": {\n",
    "        \"name\": \"Midnight\",\n",
    "        \"bgGradient\": [\"#0f0c29\", \"#302b63\"],\n",
    "        \"textColor\": \"#ffffff\",\n",
    "        \"accentColor\": \"#f5576c\",\n",
    "        \"fontFamily\": \"sans-serif\"\n",
    "    },\n",
    "    \"scenes\": [\n",
    "        {\n",
    "            \"type\": \"intro\",\n",
    "            \"duration\": 90,\n",
    "            \"props\": {\"hook\": \"Stop scrolling.\", \"subtitle\": \"This changes everything\"},\n",
    "            \"tts\": {\"text\": \"Stop scrolling. This is going to change everything you know about productivity.\", \"speaker\": \"Ryan\", \"instruct\": \"Dramatic, attention-grabbing, confident.\"}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"kinetic-text\",\n",
    "            \"duration\": 120,\n",
    "            \"props\": {\"lines\": [\"Most people waste\", \"3 HOURS a day\", \"on tasks AI can do\", \"in 3 MINUTES\"], \"accentLineIndex\": 1, \"animation\": \"slide-up\"},\n",
    "            \"tts\": {\"text\": \"Most people waste three hours every single day on tasks that AI can finish in just three minutes.\", \"speaker\": \"Ryan\", \"instruct\": \"Building intensity, emphasize the contrast.\"}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"stat-card\",\n",
    "            \"duration\": 120,\n",
    "            \"props\": {\"title\": \"The Numbers Don't Lie\", \"stats\": [{\"value\": \"87%\", \"label\": \"Time Saved\"}, {\"value\": \"10x\", \"label\": \"More Output\"}, {\"value\": \"$0\", \"label\": \"Extra Cost\"}]},\n",
    "            \"tts\": {\"text\": \"Eighty-seven percent time saved. Ten times more output. And it costs you absolutely nothing extra.\", \"speaker\": \"Ryan\", \"instruct\": \"Confident, impressive.\"}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"list-reveal\",\n",
    "            \"duration\": 150,\n",
    "            \"props\": {\"title\": \"Top 3 AI Tools\", \"items\": [\"ChatGPT for writing\", \"Midjourney for design\", \"Cursor for coding\"], \"icon\": \"üöÄ\", \"numbered\": true},\n",
    "            \"tts\": {\"text\": \"Here are the top three AI tools you need right now. Number one: ChatGPT for writing. Number two: Midjourney for design. And number three: Cursor for coding.\", \"speaker\": \"Ryan\", \"instruct\": \"Enthusiastic, clear pauses between items.\"}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"quote-card\",\n",
    "            \"duration\": 120,\n",
    "            \"props\": {\"quote\": \"AI won't replace you. But someone using AI will.\", \"author\": \"Tech Industry\", \"role\": \"Common saying\"},\n",
    "            \"tts\": {\"text\": \"Remember this: AI won't replace you. But someone using AI, definitely will.\", \"speaker\": \"Ryan\", \"instruct\": \"Thoughtful pause before the punchline, serious tone.\"}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"cta\",\n",
    "            \"duration\": 90,\n",
    "            \"props\": {\"headline\": \"Start Today\", \"subtext\": \"Follow for more AI tips\", \"buttonText\": \"Follow ‚Üí\"},\n",
    "            \"tts\": {\"text\": \"Follow for more AI tips that actually save you time. See you in the next one.\", \"speaker\": \"Ryan\", \"instruct\": \"Warm, inviting, friendly call to action.\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "total = sum(s['duration'] for s in VIDEO_CONFIG['scenes'])\n",
    "print(f\"üìã {len(VIDEO_CONFIG['scenes'])} scenes ¬∑ {total} frames ¬∑ {total/30:.1f}s\")\n",
    "for i, s in enumerate(VIDEO_CONFIG['scenes']):\n",
    "    print(f\"  {i+1}. [{s['type']}] {s['duration']/30:.1f}s ‚Äî {s['tts']['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 ‚Äî Generate Voiceover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "AUDIO_DIR = f\"{REPO}/public/audio\"\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = None  # will be set from first generation\n",
    "\n",
    "for i, scene in enumerate(VIDEO_CONFIG['scenes']):\n",
    "    tts = scene['tts']\n",
    "    print(f\"üéôÔ∏è Scene {i+1}/{len(VIDEO_CONFIG['scenes'])} [{scene['type']}] {tts['speaker']}\")\n",
    "    \n",
    "    wavs, sr = model.generate_custom_voice(\n",
    "        text=tts['text'], language='English',\n",
    "        speaker=tts['speaker'], instruct=tts.get('instruct', '')\n",
    "    )\n",
    "    if SAMPLE_RATE is None:\n",
    "        SAMPLE_RATE = sr\n",
    "    \n",
    "    audio_file = f\"{AUDIO_DIR}/scene_{i:03d}.wav\"\n",
    "    sf.write(audio_file, wavs[0], sr, subtype='PCM_16')  # PCM_16 for max compatibility\n",
    "    dur = len(wavs[0]) / sr\n",
    "    scene['_audio_dur'] = dur\n",
    "    print(f\"   ‚úÖ {dur:.1f}s\")\n",
    "\n",
    "print(f\"\\nüîä Preview last scene:\")\n",
    "display(Audio(wavs[0], rate=sr))\n",
    "print(f\"\\n‚úÖ All audio generated (sample rate: {SAMPLE_RATE} Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5 ‚Äî Adjust Durations + Build Full Audio Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30\n",
    "PAD = 15  # 0.5s padding per scene\n",
    "\n",
    "audio_parts = []\n",
    "print(\"‚è±Ô∏è Matching scene durations to audio:\\n\")\n",
    "\n",
    "for i, scene in enumerate(VIDEO_CONFIG['scenes']):\n",
    "    audio_dur = scene.get('_audio_dur', scene['duration'] / FPS)\n",
    "    needed_frames = int(audio_dur * FPS) + PAD\n",
    "    scene['duration'] = max(needed_frames, scene['duration'])\n",
    "    scene_dur_s = scene['duration'] / FPS\n",
    "    \n",
    "    # Read audio and pad to match scene duration\n",
    "    audio_file = f\"{AUDIO_DIR}/scene_{i:03d}.wav\"\n",
    "    data, sr = sf.read(audio_file, dtype='float32')\n",
    "    target_len = int(scene_dur_s * sr)\n",
    "    \n",
    "    if len(data) < target_len:\n",
    "        data = np.concatenate([data, np.zeros(target_len - len(data), dtype=np.float32)])\n",
    "    else:\n",
    "        data = data[:target_len]\n",
    "    \n",
    "    audio_parts.append(data)\n",
    "    print(f\"  Scene {i+1}: audio {audio_dur:.1f}s ‚Üí video {scene_dur_s:.1f}s\")\n",
    "\n",
    "# Concatenate and save as PCM_16 WAV (universal compatibility)\n",
    "full_audio = np.concatenate(audio_parts)\n",
    "FULL_AUDIO = f\"{AUDIO_DIR}/full_narration.wav\"\n",
    "sf.write(FULL_AUDIO, full_audio, sr, subtype='PCM_16')\n",
    "\n",
    "total_frames = sum(s['duration'] for s in VIDEO_CONFIG['scenes'])\n",
    "print(f\"\\nüìä Video: {total_frames} frames = {total_frames/FPS:.1f}s\")\n",
    "print(f\"üìä Audio: {len(full_audio)/sr:.1f}s ({os.path.getsize(FULL_AUDIO)/1e6:.1f} MB)\")\n",
    "print(f\"\\nüîä Full audio preview:\")\n",
    "display(Audio(full_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 ‚Äî Render Video (Remotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "CONFIG_FILE = f\"{REPO}/render-config.json\"\n",
    "VIDEO_SILENT = f\"{REPO}/out/video-silent.mp4\"\n",
    "os.makedirs(f\"{REPO}/out\", exist_ok=True)\n",
    "\n",
    "# Write Remotion config (only template props, no TTS fields)\n",
    "remotion_config = {\n",
    "    \"theme\": VIDEO_CONFIG[\"theme\"],\n",
    "    \"scenes\": [{\"type\": s[\"type\"], \"duration\": s[\"duration\"], \"props\": s[\"props\"]} for s in VIDEO_CONFIG[\"scenes\"]]\n",
    "}\n",
    "with open(CONFIG_FILE, 'w') as f:\n",
    "    json.dump(remotion_config, f, indent=2)\n",
    "\n",
    "total = sum(s['duration'] for s in remotion_config['scenes'])\n",
    "print(f\"üé¨ Rendering {total} frames ({total/30:.1f}s)...\\n\")\n",
    "\n",
    "# Use Remotion CLI (handles browser internally)\n",
    "!cd {REPO} && npx remotion render src/index.ts SocialVideo {VIDEO_SILENT} \\\n",
    "  --props render-config.json \\\n",
    "  --enable-multi-process-on-linux \\\n",
    "  --log=warning \\\n",
    "  2>&1\n",
    "\n",
    "if os.path.exists(VIDEO_SILENT):\n",
    "    mb = os.path.getsize(VIDEO_SILENT) / 1e6\n",
    "    print(f\"\\n‚úÖ Silent video: {mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Render failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 ‚Äî Merge Audio + Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "FINAL = f\"{REPO}/out/final-video.mp4\"\n",
    "\n",
    "# First verify audio file is valid\n",
    "print(\"üîç Checking audio...\")\n",
    "r = subprocess.run(['ffprobe', '-v', 'error', '-show_entries', 'stream=codec_type,sample_rate,channels,duration',\n",
    "                    '-of', 'compact', FULL_AUDIO], capture_output=True, text=True)\n",
    "print(f\"   {r.stdout.strip()}\")\n",
    "\n",
    "print(\"üîç Checking video...\")\n",
    "r = subprocess.run(['ffprobe', '-v', 'error', '-show_entries', 'stream=codec_type,width,height,duration',\n",
    "                    '-of', 'compact', VIDEO_SILENT], capture_output=True, text=True)\n",
    "print(f\"   {r.stdout.strip()}\")\n",
    "\n",
    "# Merge: convert audio to AAC, copy video stream\n",
    "print(\"\\nüîä Merging...\")\n",
    "cmd = [\n",
    "    'ffmpeg', '-y',\n",
    "    '-i', VIDEO_SILENT,       # video input\n",
    "    '-i', FULL_AUDIO,         # audio input\n",
    "    '-map', '0:v:0',          # take video from first input\n",
    "    '-map', '1:a:0',          # take audio from second input\n",
    "    '-c:v', 'copy',           # copy video (no re-encode)\n",
    "    '-c:a', 'aac',            # encode audio as AAC\n",
    "    '-b:a', '192k',           # audio bitrate\n",
    "    '-ac', '1',               # mono (TTS is mono)\n",
    "    '-ar', '44100',           # standard sample rate\n",
    "    '-shortest',              # match shortest stream\n",
    "    FINAL\n",
    "]\n",
    "r = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if os.path.exists(FINAL):\n",
    "    mb = os.path.getsize(FINAL) / 1e6\n",
    "    # Verify the final file has both streams\n",
    "    r2 = subprocess.run(['ffprobe', '-v', 'error', '-show_entries', 'stream=codec_type',\n",
    "                         '-of', 'csv=p=0', FINAL], capture_output=True, text=True)\n",
    "    streams = r2.stdout.strip().split('\\n')\n",
    "    has_video = 'video' in streams\n",
    "    has_audio = 'audio' in streams\n",
    "    print(f\"\\n‚úÖ Final: {FINAL} ({mb:.1f} MB)\")\n",
    "    print(f\"   Video: {'‚úÖ' if has_video else '‚ùå'} | Audio: {'‚úÖ' if has_audio else '‚ùå'}\")\n",
    "    if not has_audio:\n",
    "        print(f\"\\n‚ö†Ô∏è Audio stream missing! FFmpeg stderr:\\n{r.stderr[-500:]}\")\n",
    "else:\n",
    "    print(f\"‚ùå Merge failed:\\n{r.stderr[-500:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8 ‚Äî Preview + Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "if os.path.exists(FINAL) and os.path.getsize(FINAL) > 100000:\n",
    "    mp4 = open(FINAL, 'rb').read()\n",
    "    b64 = b64encode(mp4).decode()\n",
    "    display(HTML(f'<video width=\"360\" height=\"640\" controls><source src=\"data:video/mp4;base64,{b64}\" type=\"video/mp4\"></video>'))\n",
    "else:\n",
    "    print(\"Video too small or missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(FINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üí° Quick Reference\n",
    "\n",
    "**To re-render with changes:** edit Step 3, then run Steps 4‚Üí8\n",
    "\n",
    "| Speaker | Voice | Best For |\n",
    "|---------|-------|----------|\n",
    "| Ryan | Dynamic male | Energy, narration |\n",
    "| Aiden | Sunny American male | Casual, friendly |\n",
    "| Vivian | Bright young female | Punchy, engaging |\n",
    "| Serena | Warm gentle female | Calm, storytelling |\n",
    "| Ono_Anna | Playful female | Japanese |\n",
    "| Sohee | Warm female | Korean |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "name": "Social Video Engine ‚Äî Qwen3-TTS + Remotion"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
